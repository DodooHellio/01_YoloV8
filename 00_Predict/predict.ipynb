{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove notebook Warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-reloard and better matplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cvzone\n",
    "from ultralytics import YOLO\n",
    "import time\n",
    "from IPython.display import Video\n",
    "from screeninfo import get_monitors\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of connected monitors\n",
    "monitors = get_monitors()\n",
    "\n",
    "# Get the dimensions of the first monitor\n",
    "monitor = monitors[0]\n",
    "monitor_width = monitor.width\n",
    "monitor_height = monitor.height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"P1077418_Balcon_4K25FPS.MP4\"\n",
    "\n",
    "mask_name = \"P1077418_Balcon_4K25FPS_MASK.jpg\"\n",
    "apply_mask = True\n",
    "display_mask = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "facemodel_path = os.path.join(os.path.dirname(os.getcwd()), \"Model/yolov8n-face.pt\")\n",
    "if os.path.exists(facemodel_path):\n",
    "    facemodel = YOLO(facemodel_path)\n",
    "    pass\n",
    "else :\n",
    "    raise FileExistsError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path video to analyse and check file exist in ./Videos/video_name\n",
    "file_video_path = os.path.join(os.path.dirname(os.getcwd()), \"Videos\", video_name )\n",
    "if os.path.exists(file_video_path):\n",
    "    pass\n",
    "else :\n",
    "    raise FileExistsError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(file_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "delay = int(1000 / fps)\n",
    "\n",
    "\n",
    "video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if apply_mask :\n",
    "\n",
    "    mask_path = os.path.join(os.path.dirname(os.getcwd()), \"Videos\", mask_name )\n",
    "\n",
    "    if os.path.exists(mask_path):\n",
    "        mask = cv2.imread(mask_path)\n",
    "\n",
    "        mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "        _, mask_binary = cv2.threshold(mask_gray, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    else:\n",
    "        raise FileExistsError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Video and detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 3 faces, 85.6ms\n",
      "Speed: 346.4ms preprocess, 85.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 26.0ms\n",
      "Speed: 4.6ms preprocess, 26.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 25.4ms\n",
      "Speed: 5.5ms preprocess, 25.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 15.0ms\n",
      "Speed: 2.8ms preprocess, 15.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 faces, 15.7ms\n",
      "Speed: 3.8ms preprocess, 15.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 17.4ms\n",
      "Speed: 4.4ms preprocess, 17.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 17.6ms\n",
      "Speed: 3.2ms preprocess, 17.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 26.6ms\n",
      "Speed: 3.6ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 16.0ms\n",
      "Speed: 3.5ms preprocess, 16.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 23.7ms\n",
      "Speed: 5.3ms preprocess, 23.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 17.4ms\n",
      "Speed: 3.2ms preprocess, 17.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 14.5ms\n",
      "Speed: 3.3ms preprocess, 14.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 14.0ms\n",
      "Speed: 2.9ms preprocess, 14.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 26.2ms\n",
      "Speed: 12.9ms preprocess, 26.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 22.0ms\n",
      "Speed: 4.2ms preprocess, 22.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 faces, 21.5ms\n",
      "Speed: 4.0ms preprocess, 21.5ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 faces, 19.2ms\n",
      "Speed: 3.9ms preprocess, 19.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 faces, 20.5ms\n",
      "Speed: 9.3ms preprocess, 20.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 faces, 17.9ms\n",
      "Speed: 3.5ms preprocess, 17.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 faces, 21.2ms\n",
      "Speed: 3.2ms preprocess, 21.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 faces, 20.8ms\n",
      "Speed: 3.2ms preprocess, 20.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 faces, 23.4ms\n",
      "Speed: 3.2ms preprocess, 23.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "# Create a window with the size of the video at the calculated position\n",
    "cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)\n",
    "cv2.moveWindow(\"Image\", (video_width - monitor_width) // 2, (video_height - monitor_height) // 2)\n",
    "cv2.resizeWindow(\"Image\", monitor_width, monitor_height)\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    success, img = cap.read()\n",
    "    if success:\n",
    "\n",
    "        if apply_mask:\n",
    "            img_prepredict = cv2.bitwise_and(img, img, mask=mask_binary)\n",
    "            if display_mask:\n",
    "                img = img_prepredict\n",
    "            else :\n",
    "                pass\n",
    "\n",
    "        else :\n",
    "            img_ready = img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        face_result = facemodel.predict(img_prepredict, conf=0.40)\n",
    "        for info in face_result:\n",
    "            parameters = info.boxes\n",
    "            for box in parameters:\n",
    "                x1,y1,x2,y2 = box.xyxy[0]\n",
    "                x1,y1,x2,y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "                h,w = y2 - y1, x2 - x1\n",
    "                cvzone.cornerRect(img, [x1,y1,w,h], l=9, rt=3)\n",
    "\n",
    "\n",
    "\n",
    "        #display FPS\n",
    "        cv2.putText(img, f'FPS: {int(fps)}', (10  , video_height - 100), cv2.FONT_HERSHEY_SIMPLEX, 5, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Image\", img)\n",
    "\n",
    "        #End program\n",
    "        if cv2.waitKey(delay) == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wakep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
